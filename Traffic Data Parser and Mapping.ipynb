{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Setting up libraries for project\n",
    "    \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import folium as fm # Map Library: will only work with Jupyter since it needs a browser\n",
    "from folium.plugins import FastMarkerCluster # To add map markers\n",
    "from pyproj import Proj, transform\n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"Traffic Data\", timeout=3)\n",
    "location = geolocator.geocode(\"175 5th Avenue NYC\")\n",
    "\n",
    "\"\"\" Settings for numpy and Pandas\n",
    "\"\"\"\n",
    "#Numpy:\n",
    "np.set_printoptions(threshold = np.inf, linewidth = 500, suppress = True)\n",
    "\n",
    "#Pandas\n",
    "pd.set_option(\"display.max_rows\"\t, \t3000)\n",
    "pd.set_option(\"display.max_columns\"\t, \t3000)\n",
    "pd.set_option(\"display.width\"\t\t,\t1000)\n",
    "pd.set_option(\"display.float_format\", \tlambda x: \"%.3f' % x\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parsing for the CSV, read in all data from CSV \n",
    "\"\"\"\n",
    "def ParseFile(file_in, file_out, batchsize):\n",
    "    \"\"\" \n",
    "    Recieve CSV file, parse data, then output new CSV organized with wanted data\n",
    "    Parameter: file_in, file_out, batchsize (for larger CSVs if wanted >1mill entries)\n",
    "    Return: Outputs new CSV with desired data, nothing returned from function\n",
    "    \"\"\"\n",
    "    # Datafram for CSV\n",
    "    d = pd.read_csv(file_in, delimiter = ',', header = 0, nrows = 0, dtype = str)\n",
    "    dat_recent = pd.DataFrame(data = d)\n",
    "    # The columns that we won't be using can be dropped\n",
    "    dat_recent = dat_recent.drop(['School Zone', 'Construction Zone', 'Case Closed', 'Agency', 'Officer Code'], axis=1)\n",
    "\n",
    "    i = 0\n",
    "    not_done = True\n",
    "    # Do in batches, if more than 1 million samples\n",
    "    while not_done:\n",
    "\n",
    "        print('processing batch', i, ', samples processed: ', i * batchsize)\n",
    "\n",
    "        # load in batches of 1-million entries for processing per pass\n",
    "        dat = pd.read_csv(file_in, delimiter = ',', header = 0, nrows = batchsize, skiprows = range(1, i*batchsize),\n",
    "                          dtype = str)\n",
    "\n",
    "        # Drop the columns that we don't need to save on space\n",
    "        dat = dat.drop(['School Zone', 'Construction Zone', 'Case Closed', 'Agency', 'Officer Code'], axis=1)\n",
    "\n",
    "\n",
    "        # if the batch has less than 1-million entries then we know that this is the last pass\n",
    "        i+=1\n",
    "        if len(dat) < batchsize:\n",
    "            not_done = False\n",
    "\n",
    "        # replace the emply fields with \"0\"\n",
    "        dat = dat.replace(np.nan, '0')\n",
    "\n",
    "        # Extract 2018 stuff and convert address to coordinates while storing into csv\n",
    "        #print(location)\n",
    "        dat = dat[dat['Offense Date'].str.contains('2018')]\n",
    "        #dat[\"Latitude\"]\n",
    "        dat[\"Offense Street Name\"] = dat[\"Offense Street Name\"] + \" Austin\"\n",
    "        location = geolocator.geocode(dat[\"Offense Street Name\"], timeout=20)\n",
    "        #dat[\"Coordinates\"]\n",
    "       \n",
    "\n",
    "        dat_recent = dat_recent.append(dat)\n",
    "\n",
    "\n",
    "    # print(dat_recent)\n",
    "    dat_recent.to_csv(file_out)\n",
    "    print('done, new .csv saved as', file_out)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 0 , samples processed:  0\n"
     ]
    },
    {
     "ename": "GeocoderServiceError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mERROR_CODE_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGeocoderServiceError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-e731cf329bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrim_data\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[1;31m# ParseFile('Municipal_Court_Caseload_Information_FY_2018.csv', 'Output2018.csv', batchsize)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mParseFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Output2018.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m# Load in the cleaned data as its own dataframe to work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-b4ecff3c95bc>\u001b[0m in \u001b[0;36mParseFile\u001b[1;34m(file_in, file_out, batchsize)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#dat[\"Latitude\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Offense Street Name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Offense Street Name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" Austin\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Offense Street Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;31m#dat[\"Coordinates\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\u001b[0m in \u001b[0;36mgeocode\u001b[1;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         return self._parse_json(\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         )\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mERROR_CODE_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mGeocoderServiceError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"timed out\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGeocoderServiceError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "\"\"\"Main Program\n",
    "    Runs mapping library\n",
    "\"\"\"\n",
    "\n",
    "# To keep track of how long it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# No need to run either if the csv's are already made\n",
    "batchsize = 150000\n",
    "trim_data = True\n",
    "\n",
    "if trim_data == True:\n",
    "   # ParseFile('Municipal_Court_Caseload_Information_FY_2018.csv', 'Output2018.csv', batchsize)\n",
    "    ParseFile(\"test.csv\", \"Output2018.csv\", batchsize)\n",
    "# Load in the cleaned data as its own dataframe to work with\n",
    "print('Loading data...')\n",
    "working_data = pd.read_csv('Output2018.csv', delimiter=',', header=0, dtype = object)\n",
    "\n",
    "# Rename the first column which is duplicated upon loading the csv (csv saves the index and loading it in adds an index)\n",
    "working_data = working_data.rename(columns = {'Unnamed: 0' : 'Index'})\n",
    "\n",
    "print('Data loaded, producing figures and maps...')\n",
    "\n",
    "# - - - - - - - - - - - - - - - - For the map: - - - - - - - - - - - - - - - -\n",
    "\n",
    "# Take the coorinates as their own dataframe so it can be manipulated, no need to throw out the rows with bad\n",
    "# coordinate data from the full data set since they may contain other useful info\n",
    "\n",
    "cbatch = 40000 # Number of previous incidents to plot, anything over this will bog down the map\n",
    "coords = (working_data.loc[(len(working_data) - cbatch):, \"Offense Street Name\"]).astype(dtype = \"str\")\n",
    "\n",
    "\n",
    "# # coords are in x/y and we want lat/long, this is from the pyproj documentation\n",
    "# pm = '+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 ' \\\n",
    "#      '+y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs'\n",
    "\n",
    "# # convert to lat/long\n",
    "# x_in,y_in = coords['Latitude'].values, coords['Longitude'].values\n",
    "# lat,long = transform(Proj(pm, preserve_units = True), Proj(\"+init=epsg:4326\"), x_in,y_in)\n",
    "\n",
    "# LA_coords = [34.05 , -118.24]\n",
    "# m = fm.Map(location=LA_coords, zoom_start=10.5)\n",
    "\n",
    "# # add map markers, plots as \"long/lat\" rather than \"lat/long\"\n",
    "# FastMarkerCluster(data=list(zip(long, lat))).add_to(m)\n",
    "# display(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 0 , samples processed:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '/2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dbb275de41db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleanCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OutputClean.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-73fa3b8ebfef>\u001b[0m in \u001b[0;36mcleanCSV\u001b[1;34m(file_in, file_out, batchsize)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             hold_dict[idx] = [int(dat.at[idx,'Offense Date'][3]), int(dat.at[idx,'Offense Date'][5:7]), int(dat.at[idx,\n\u001b[0m\u001b[0;32m     39\u001b[0m                                                                                             'Offense Date'][8:10])]\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '/2'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
