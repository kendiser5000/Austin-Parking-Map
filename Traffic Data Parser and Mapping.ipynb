{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Setting up libraries for project\n",
    "    \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import folium as fm # Map Library: will only work with Jupyter since it needs a browser\n",
    "from folium.plugins import FastMarkerCluster # To add map markers\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "\n",
    "\"\"\" Settings for numpy and Pandas\n",
    "\"\"\"\n",
    "#Numpy:\n",
    "np.set_printoptions(threshold = np.inf, linewidth = 500, suppress = True)\n",
    "\n",
    "#Pandas\n",
    "pd.set_option(\"display.max_rows\"\t, \t3000)\n",
    "pd.set_option(\"display.max_columns\"\t, \t3000)\n",
    "pd.set_option(\"display.width\"\t\t,\t1000)\n",
    "pd.set_option(\"display.float_format\", \tlambda x: \"%.3f' % x\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parsing for the CSV, read in all data from CSV \n",
    "\"\"\"\n",
    "def ParseFile(file_in, file_out, batchsize):\n",
    "    \"\"\" \n",
    "    Recieve CSV file, parse data, then output new CSV organized with wanted data\n",
    "    Parameter: file_in, file_out, batchsize (for larger CSVs if wanted >1mill entries)\n",
    "    Return: Outputs new CSV with desired data, nothing returned from function\n",
    "    \"\"\"\n",
    "    # Datafram for CSV\n",
    "    d = pd.read_csv(file_in, delimiter = ',', header = 0, nrows = 0, dtype = str)\n",
    "    dat_recent = pd.DataFrame(data = d)\n",
    "\n",
    "    # The columns that we won't be using can be dropped\n",
    "    dat_recent = dat_recent.drop(['School Zone', 'Construction Zone', 'Case Closed', 'Agency', 'Officer Code'], axis=1)\n",
    "\n",
    "    i = 0\n",
    "    not_done = True\n",
    "    # Do in batches, if more than 1 million samples\n",
    "    while not_done:\n",
    "\n",
    "        print('processing batch', i, ', samples processed: ', i * batchsize)\n",
    "\n",
    "        # load in batches of 1-million entries for processing per pass\n",
    "        dat = pd.read_csv(file_in, delimiter = ',', header = 0, nrows = batchsize, skiprows = range(1, i*batchsize),\n",
    "                          dtype = str)\n",
    "\n",
    "        # Drop the columns that we don't need to save on space\n",
    "        dat = dat.drop(['School Zone', 'Construction Zone', 'Case Closed', 'Agency', 'Officer Code'], axis=1)\n",
    "\n",
    "\n",
    "        # if the batch has less than 1-million entries then we know that this is the last pass\n",
    "        i+=1\n",
    "        if len(dat) < batchsize:\n",
    "            not_done = False\n",
    "\n",
    "        # replace the emply fields with \"0\"\n",
    "        dat = dat.replace(np.nan, '0')\n",
    "\n",
    "        # Extract 2018 stuff\n",
    "        dat = dat[dat['Offense Date'].str.contains('2018')]\n",
    "        dat_recent = dat_recent.append(dat)\n",
    "\n",
    "    # print(dat_recent)\n",
    "    dat_recent.to_csv(file_out)\n",
    "    print('done, new .csv saved as', file_out)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-7ccbb1f4396d>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-7ccbb1f4396d>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    'Offense Date'][8:10])]\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main Program\n",
    "    Runs mapping library\n",
    "\"\"\"\n",
    "\n",
    "# To keep track of how long it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# No need to run either if the csv's are already made\n",
    "batchsize = 150000\n",
    "trim_data = True\n",
    "\n",
    "if trim_data == True:\n",
    "    trimData('Municipal_Court_Caseload_Information_FY_2018.csv', 'Output2018.csv', batchsize)\n",
    "\n",
    "# Load in the cleaned data as its own dataframe to work with\n",
    "print('Loading data...')\n",
    "working_data = pd.read_csv('Output2018.csv', delimiter=',', header=0, dtype = object)\n",
    "\n",
    "# Rename the first column which is duplicated upon loading the csv (csv saves the index and loading it in adds an index)\n",
    "working_data = working_data.rename(columns = {'Unnamed: 0' : 'Index'})\n",
    "\n",
    "print('Data loaded, producing figures and maps...')\n",
    "\n",
    "# - - - - - - - - - - - - - - - - For the map: - - - - - - - - - - - - - - - -\n",
    "\n",
    "# Take the coorinates as their own dataframe so it can be manipulated, no need to throw out the rows with bad\n",
    "# coordinate data from the full data set since they may contain other useful info\n",
    "\n",
    "cbatch = 40000 # Number of previous incidents to plot, anything over this will bog down the map\n",
    "coords = (working_data.loc[(len(working_data) - cbatch):, Offense Street Name + 'Austin']).astype(string)\n",
    "\n",
    "\n",
    "# coords are in x/y and we want lat/long, this is from the pyproj documentation\n",
    "pm = '+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 ' \\\n",
    "     '+y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs'\n",
    "\n",
    "# convert to lat/long\n",
    "x_in,y_in = coords['Latitude'].values, coords['Longitude'].values\n",
    "lat,long = transform(Proj(pm, preserve_units = True), Proj(\"+init=epsg:4326\"), x_in,y_in)\n",
    "\n",
    "LA_coords = [34.05 , -118.24]\n",
    "m = fm.Map(location=LA_coords, zoom_start=10.5)\n",
    "\n",
    "# add map markers, plots as \"long/lat\" rather than \"lat/long\"\n",
    "FastMarkerCluster(data=list(zip(long, lat))).add_to(m)\n",
    "display(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 0 , samples processed:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '/2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dbb275de41db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleanCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OutputClean.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-73fa3b8ebfef>\u001b[0m in \u001b[0;36mcleanCSV\u001b[1;34m(file_in, file_out, batchsize)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             hold_dict[idx] = [int(dat.at[idx,'Offense Date'][3]), int(dat.at[idx,'Offense Date'][5:7]), int(dat.at[idx,\n\u001b[0m\u001b[0;32m     39\u001b[0m                                                                                             'Offense Date'][8:10])]\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '/2'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
